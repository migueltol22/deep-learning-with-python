{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepdream.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_ooInAYN06zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eff27a33-2165-4783-8cd5-e034392bcf71"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import inception_v3\n",
        "from keras import backend as K\n",
        "\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yiAk0-Qp09gY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa9c9fb6-35a2-4a7a-ca51-0880c1bec5e8"
      },
      "cell_type": "code",
      "source": [
        "layer_contributions = {\n",
        "    'mixed2': 0.2,\n",
        "    'mixed3': 3.,\n",
        "    'mixed4': 2.,\n",
        "    'mixed5': 1.5,\n",
        "}\n",
        "\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "loss = K.variable(0.)\n",
        "for layer_name in layer_contributions:\n",
        "  coeff = layer_contributions[layer_name]\n",
        "  activation = layer_dict[layer_name].output\n",
        "  \n",
        "  scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
        "  loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k0w3A9AY1EzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gradient ascent process\n",
        "dream = model.input\n",
        "grads = K.gradients(loss, dream)[0]\n",
        "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
        "\n",
        "outputs = [loss, grads]\n",
        "fetch_loss_and_grads = K.function([dream], outputs)\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "  outs = fetch_loss_and_grads([x])\n",
        "  loss_value = outs[0]\n",
        "  grad_values = outs[1]\n",
        "  return loss_value, grad_values\n",
        "\n",
        "def gradient_ascent(x, iterations, step, max_loss=None):\n",
        "  for i in range(iterations):\n",
        "    loss_value, grad_values = eval_loss_and_grads(x)\n",
        "    if max_loss is not None and loss_value > max_loss:\n",
        "      break\n",
        "    print('..Loss value at', i, ':', loss_value)\n",
        "    x += step * grad_values\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9w7_R6t9Qsb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def resize_img(img, size):\n",
        "  img = np.copy(img)\n",
        "  factors = (1,\n",
        "             float(size[0]) / img.shape[1],\n",
        "             float(size[1]) / img.shape[2],\n",
        "             1)\n",
        "  return scipy.ndimage.zoom(img, factors, order=1)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  img = image.load_img(image_path)\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    x = x.reshape((3, x.shape[2], x.shape[3]))\n",
        "    x = x.transpose((1, 2, 0))\n",
        "  else:\n",
        "    x = x.reshape((x.shape[1], x.shape[2], 3))\n",
        "  x /= 2.\n",
        "  x += 0.5\n",
        "  x *= 255\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x\n",
        "    \n",
        "\n",
        "def save_img(img, fname):\n",
        "  pil_img = deprocess_image(np.copy(img))\n",
        "  scipy.misc.imsave(fname, pil_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vE5MZrx95WKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# running gradient ascent over different successive scales\n",
        "import numpy as np\n",
        "\n",
        "step = 0.01\n",
        "num_octave = 3\n",
        "octave_scale = 1.4\n",
        "iterations = 20\n",
        "\n",
        "max_loss = 10.\n",
        "\n",
        "base_image_path = 'insert_image_path'\n",
        "img = preprocess_image(base_image_path)\n",
        "\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "for i in range(1, num_octave):\n",
        "  shape = tuple([int(dim / (octave_scale ** i))\n",
        "                for dim in original_shape])\n",
        "  successive_shapes.append(shape)\n",
        "\n",
        "successive_shapes = successive_shapes[::-1]\n",
        "\n",
        "original_img = np.copy(img)\n",
        "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
        "\n",
        "for shape in successive_shapes:\n",
        "  print('Processing image shape', shape)\n",
        "  img = resize_img(img, shape)\n",
        "  img = gradient_ascent(img,\n",
        "                        iterations=iterations,\n",
        "                        step=step,\n",
        "                        max_loss=max_loss)\n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
        "  same_size_original = resize_img(original_img, shape)\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img\n",
        "  \n",
        "  img += lost_detail\n",
        "  shrunk_original_img = resize_img(original_img, shape)\n",
        "  save_img(img, fname-'dream_at_scale' + str(shape) + '.png')\n",
        "  \n",
        "save_img(img, fname='final_dream.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}